11/04/2025 13:20:30 - INFO - accelerate.utils.modeling -   We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
11/04/2025 13:20:54 - INFO - root -   number of sec samples before upsampling: 1809
11/04/2025 13:20:54 - INFO - root -   number of sec samples after upsampling: 3344
11/04/2025 13:20:57 - INFO - root -   Training args Namespace(output_name='phi-2-safecoder', datasets=['lmsys', 'sec-desc', 'sec-new-desc'], pretrain_name='phi-2', loss_weight=1.0, sven=False, num_train_epochs=2, learning_rate=2e-05, max_num_tokens=1024, batch_size=1, grad_acc_steps=16, weight_decay=0.01, adam_epsilon=1e-08, warmup_steps=0, max_grad_norm=1.0, dropout=0.1, kl_loss_weight=0, exclude_neg=False, no_weights=False, lora=False, r=16, lora_alpha=32, lora_dropout=0.1, sampling_size=40, sampling_method='minority', cwes=['all'], langs=['all'], logging_steps=50, save_epochs=10, seed=2, data_dir='../data_train_val', model_dir='../trained/', output_dir='../trained/phi-2-safecoder', logger=<RootLogger root (INFO)>)
11/04/2025 13:20:57 - INFO - root -   ***** Running training *****
11/04/2025 13:20:57 - INFO - root -     Num samples = 19626
11/04/2025 13:20:57 - INFO - root -     Num epoch = 2
11/04/2025 13:20:57 - INFO - root -     Batch size= 1
11/04/2025 13:20:57 - INFO - root -     Total batch size (w. accumulation) = 16
11/04/2025 13:20:57 - INFO - root -     Gradient Accumulation steps = 16
11/04/2025 13:20:57 - INFO - root -     Total optimization steps = 2452
11/04/2025 13:20:57 - INFO - root -     Num val samples = 2008
11/04/2025 13:20:57 - INFO - root -     Num parameters = 2775049335
11/04/2025 13:20:57 - INFO - root -     Num trainable parameters = 2775049335
11/04/2025 13:26:32 - INFO - root -   epochs: 1/2, steps: 50/2452, func: 0.077716, pos: 0.124142, neg: 0.062682, 1%: 4h 29m 35s          
11/04/2025 13:32:04 - INFO - root -   epochs: 1/2, steps: 100/2452, func: 0.075514, pos: 0.092357, neg: 0.050567, 4%: 4h 21m 30s          
11/04/2025 13:37:36 - INFO - root -   epochs: 1/2, steps: 150/2452, func: 0.072411, pos: 0.10402, neg: 0.041028, 6%: 4h 16m 4s          
11/04/2025 13:43:16 - INFO - root -   epochs: 1/2, steps: 200/2452, func: 0.072258, pos: 0.084403, neg: 0.024777, 8%: 4h 11m 9s          
11/04/2025 13:48:41 - INFO - root -   epochs: 1/2, steps: 250/2452, func: 0.071785, pos: 0.082214, neg: 0.022354, 10%: 4h 4m 22s          
11/04/2025 13:54:12 - INFO - root -   epochs: 1/2, steps: 300/2452, func: 0.071116, pos: 0.077579, neg: 0.023102, 12%: 3h 58m 26s          
11/04/2025 13:59:37 - INFO - root -   epochs: 1/2, steps: 350/2452, func: 0.070133, pos: 0.074148, neg: 0.026123, 14%: 3h 52m 30s          
11/04/2025 14:05:12 - INFO - root -   epochs: 1/2, steps: 400/2452, func: 0.070419, pos: 0.073626, neg: 0.027343, 16%: 3h 47m 7s          
11/04/2025 14:10:37 - INFO - root -   epochs: 1/2, steps: 450/2452, func: 0.067769, pos: 0.072549, neg: 0.024669, 18%: 3h 41m 7s          
11/04/2025 14:16:13 - INFO - root -   epochs: 1/2, steps: 500/2452, func: 0.068125, pos: 0.083476, neg: 0.021869, 20%: 3h 35m 54s          
11/04/2025 14:21:31 - INFO - root -   epochs: 1/2, steps: 550/2452, func: 0.067753, pos: 0.053262, neg: 0.018116, 22%: 3h 29m 32s          
11/04/2025 14:27:07 - INFO - root -   epochs: 1/2, steps: 600/2452, func: 0.065421, pos: 0.060267, neg: 0.015661, 24%: 3h 24m 23s          
11/04/2025 14:32:39 - INFO - root -   epochs: 1/2, steps: 650/2452, func: 0.066733, pos: 0.062019, neg: 0.012771, 26%: 3h 18m 51s          
11/04/2025 14:38:13 - INFO - root -   epochs: 1/2, steps: 700/2452, func: 0.067408, pos: 0.086194, neg: 0.022271, 28%: 3h 13m 32s          
11/04/2025 14:43:44 - INFO - root -   epochs: 1/2, steps: 750/2452, func: 0.065832, pos: 0.071082, neg: 0.01781, 30%: 3h 8m 0s          
11/04/2025 14:49:11 - INFO - root -   epochs: 1/2, steps: 800/2452, func: 0.064312, pos: 0.04837, neg: 0.013326, 32%: 3h 2m 17s          
11/04/2025 14:54:36 - INFO - root -   epochs: 1/2, steps: 850/2452, func: 0.063605, pos: 0.063124, neg: 0.017323, 34%: 2h 56m 35s          
11/04/2025 15:00:08 - INFO - root -   epochs: 1/2, steps: 900/2452, func: 0.063899, pos: 0.043446, neg: 0.018097, 36%: 2h 51m 7s          
11/04/2025 15:05:42 - INFO - root -   epochs: 1/2, steps: 950/2452, func: 0.064561, pos: 0.052363, neg: 0.011071, 38%: 2h 45m 42s          
11/04/2025 15:11:23 - INFO - root -   epochs: 1/2, steps: 1000/2452, func: 0.066642, pos: 0.041886, neg: 0.020297, 40%: 2h 40m 27s          
11/04/2025 15:17:04 - INFO - root -   epochs: 1/2, steps: 1050/2452, func: 0.065675, pos: 0.043054, neg: 0.020042, 42%: 2h 35m 10s          
11/04/2025 15:22:36 - INFO - root -   epochs: 1/2, steps: 1100/2452, func: 0.063468, pos: 0.043513, neg: 0.027245, 44%: 2h 29m 38s          
11/04/2025 15:28:05 - INFO - root -   epochs: 1/2, steps: 1150/2452, func: 0.066496, pos: 0.045125, neg: 0.012837, 46%: 2h 24m 3s          
11/04/2025 15:33:34 - INFO - root -   epochs: 1/2, steps: 1200/2452, func: 0.063967, pos: 0.043816, neg: 0.011556, 48%: 2h 18m 27s          
11/04/2025 15:39:19 - INFO - root -   epochs: 2/2, steps: 1250/2452, func: 0.055663, pos: 0.046543, neg: 0.016164, 50%: 2h 13m 9s          
11/04/2025 15:44:50 - INFO - root -   epochs: 2/2, steps: 1300/2452, func: 0.048338, pos: 0.03707, neg: 0.008486, 52%: 2h 7m 36s          
11/04/2025 15:50:27 - INFO - root -   epochs: 2/2, steps: 1350/2452, func: 0.049826, pos: 0.021086, neg: 0.010234, 55%: 2h 2m 7s          
11/04/2025 15:55:56 - INFO - root -   epochs: 2/2, steps: 1400/2452, func: 0.045957, pos: 0.021281, neg: 0.010354, 57%: 1h 56m 34s          
11/04/2025 16:01:28 - INFO - root -   epochs: 2/2, steps: 1450/2452, func: 0.047487, pos: 0.024099, neg: 0.005692, 59%: 1h 51m 1s          
11/04/2025 16:07:07 - INFO - root -   epochs: 2/2, steps: 1500/2452, func: 0.048463, pos: 0.024087, neg: 0.010019, 61%: 1h 45m 34s          
11/04/2025 16:12:38 - INFO - root -   epochs: 2/2, steps: 1550/2452, func: 0.0465, pos: 0.022148, neg: 0.005987, 63%: 1h 40m 0s          
11/04/2025 16:18:09 - INFO - root -   epochs: 2/2, steps: 1600/2452, func: 0.048112, pos: 0.037928, neg: 0.006859, 65%: 1h 34m 28s          
11/04/2025 16:23:35 - INFO - root -   epochs: 2/2, steps: 1650/2452, func: 0.047311, pos: 0.023711, neg: 0.009273, 67%: 1h 28m 53s          
11/04/2025 16:29:04 - INFO - root -   epochs: 2/2, steps: 1700/2452, func: 0.047922, pos: 0.024044, neg: 0.008739, 69%: 1h 23m 20s          
11/04/2025 16:34:33 - INFO - root -   epochs: 2/2, steps: 1750/2452, func: 0.047634, pos: 0.018191, neg: 0.006465, 71%: 1h 17m 45s          
11/04/2025 16:39:50 - INFO - root -   epochs: 2/2, steps: 1800/2452, func: 0.047217, pos: 0.024217, neg: 0.008815, 73%: 1h 12m 9s          
11/04/2025 16:45:28 - INFO - root -   epochs: 2/2, steps: 1850/2452, func: 0.046857, pos: 0.015301, neg: 0.012149, 75%: 1h 6m 39s          
11/04/2025 16:50:57 - INFO - root -   epochs: 2/2, steps: 1900/2452, func: 0.04779, pos: 0.017223, neg: 0.007074, 77%: 1h 1m 7s          
11/04/2025 16:56:26 - INFO - root -   epochs: 2/2, steps: 1950/2452, func: 0.047239, pos: 0.029257, neg: 0.00501, 79%: 0h 55m 35s          
11/04/2025 17:01:55 - INFO - root -   epochs: 2/2, steps: 2000/2452, func: 0.046326, pos: 0.030557, neg: 0.008853, 81%: 0h 50m 3s          
11/04/2025 17:07:12 - INFO - root -   epochs: 2/2, steps: 2050/2452, func: 0.043911, pos: 0.028332, neg: 0.009015, 83%: 0h 44m 29s          
11/04/2025 17:12:39 - INFO - root -   epochs: 2/2, steps: 2100/2452, func: 0.046222, pos: 0.017462, neg: 0.012026, 85%: 0h 38m 56s          
11/04/2025 17:18:15 - INFO - root -   epochs: 2/2, steps: 2150/2452, func: 0.049143, pos: 0.012372, neg: 0.006403, 87%: 0h 33m 26s          
11/04/2025 17:23:50 - INFO - root -   epochs: 2/2, steps: 2200/2452, func: 0.047159, pos: 0.015025, neg: 0.010835, 89%: 0h 27m 55s          
11/04/2025 17:29:17 - INFO - root -   epochs: 2/2, steps: 2250/2452, func: 0.04719, pos: 0.014676, neg: 0.010013, 91%: 0h 22m 24s          
11/04/2025 17:34:47 - INFO - root -   epochs: 2/2, steps: 2300/2452, func: 0.046372, pos: 0.022097, neg: 0.006854, 93%: 0h 16m 53s          
11/04/2025 17:40:16 - INFO - root -   epochs: 2/2, steps: 2350/2452, func: 0.046092, pos: 0.028403, neg: 0.004337, 95%: 0h 11m 21s          
11/04/2025 17:45:57 - INFO - root -   epochs: 2/2, steps: 2400/2452, func: 0.046771, pos: 0.018487, neg: 0.005988, 97%: 0h 5m 51s          
11/04/2025 17:51:41 - INFO - root -   epochs: 2/2, steps: 2450/2452, func: 0.048451, pos: 0.020622, neg: 0.011002, 99%: 0h 0m 19s          
11/04/2025 17:56:33 - INFO - root -   final eval loss: func: 0.059705, pos: 0.063826, neg: 0.026054
11/04/2025 17:56:33 - INFO - root -   Saving model checkpoint to ../trained/phi-2-safecoder/checkpoint-last
